"""
Microsoft AutoGen Agent ç¤ºä¾‹é¡¹ç›®

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨ Microsoft AutoGen æ„å»ºå¤š Agent å¯¹è¯ç³»ç»Ÿï¼Œ
å¹¶é›†æˆåˆ° PPIO Agent Runtime ä¸­ã€‚

åŠŸèƒ½ï¼š
- ä½¿ç”¨ AutoGen æ„å»ºå¯¹è¯å¼ Agent
- æ”¯æŒå·¥å…·è°ƒç”¨å’Œåæ€
- å®Œæ•´é›†æˆ PPIO Agent Runtime
"""

import logging
import os

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv()

# å¯¼å…¥ PPIO Agent Runtime
from ppio_sandbox.agent_runtime import AgentRuntimeApp, RequestContext

app = AgentRuntimeApp()

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("autogen_agent")

# åˆå§‹åŒ–å…¨å±€å¯¹è¯å†å² - åœ¨æ²™ç®±ç”Ÿå‘½å‘¨æœŸå†…æŒä¹…åŒ–
# åŒä¸€ä¸ªæ²™ç®±å®ä¾‹çš„æ‰€æœ‰è¯·æ±‚å…±äº«æ­¤å†å²
conversation_history = []

# æ£€æŸ¥ AutoGen æ˜¯å¦å¯ç”¨
try:
    from autogen_agentchat.agents import AssistantAgent
    from autogen_agentchat.ui import Console
    from autogen_agentchat.messages import TextMessage
    from autogen_ext.models.openai import OpenAIChatCompletionClient
    from autogen_core.models import ModelFamily, ModelInfo
    from autogen_core import CancellationToken
    AUTOGEN_AVAILABLE = True
    logger.info("AutoGen å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    AUTOGEN_AVAILABLE = False
    logger.error(f"AutoGen å¯¼å…¥å¤±è´¥ï¼š{e}", exc_info=True)
    logger.warning("AutoGen æœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")


# å®šä¹‰å·¥å…·å‡½æ•°
async def get_weather(city: str) -> str:
    """
    è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”
    
    Args:
        city: åŸå¸‚åç§°
        
    Returns:
        å¤©æ°”ä¿¡æ¯å­—ç¬¦ä¸²
    """
    weather_data = {
        "åŒ—äº¬": "æ™´å¤©ï¼Œæ¸©åº¦ 15Â°Cï¼Œç©ºæ°”è´¨é‡è‰¯å¥½",
        "ä¸Šæµ·": "å¤šäº‘ï¼Œæ¸©åº¦ 20Â°Cï¼Œæ¹¿åº¦ 60%",
        "æ·±åœ³": "å°é›¨ï¼Œæ¸©åº¦ 25Â°Cï¼Œå»ºè®®å¸¦ä¼",
        "å¹¿å·": "æ™´å¤©ï¼Œæ¸©åº¦ 28Â°Cï¼Œç‚çƒ­",
    }
    return weather_data.get(city, f"{city}ï¼šæ™´å¤©ï¼Œæ¸©åº¦ 23Â°C")


async def search_information(query: str) -> str:
    """
    æœç´¢ä¿¡æ¯
    
    Args:
        query: æœç´¢æŸ¥è¯¢
        
    Returns:
        æœç´¢ç»“æœ
    """
    return f"å…³äº '{query}' çš„æœç´¢ç»“æœï¼šè¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹æœç´¢ç»“æœã€‚å®é™…ä½¿ç”¨æ—¶å¯ä»¥æ¥å…¥çœŸå®æœç´¢ APIã€‚"


async def calculate(expression: str) -> str:
    """
    è®¡ç®—æ•°å­¦è¡¨è¾¾å¼
    
    Args:
        expression: æ•°å­¦è¡¨è¾¾å¼
        
    Returns:
        è®¡ç®—ç»“æœ
    """
    try:
        result = eval(expression, {"__builtins__": {}}, {})
        return f"è®¡ç®—ç»“æœï¼š{expression} = {result}"
    except Exception as e:
        return f"è®¡ç®—é”™è¯¯ï¼š{str(e)}"


def _create_agent(streaming=False):
    """
    åˆ›å»º AutoGen Agentï¼ˆå¤ç”¨é…ç½®ï¼‰
    
    Args:
        streaming: æ˜¯å¦å¯ç”¨æµå¼è¾“å‡ºï¼ˆtoken çº§åˆ«ï¼‰
    """
    model_client = OpenAIChatCompletionClient(
        base_url=os.getenv("OPENAI_BASE_URL", "https://api.ppinfra.com/v3/openai"),
        model=os.getenv("MODEL_NAME", "deepseek/deepseek-v3.1-terminus"),
        api_key=os.getenv("OPENAI_API_KEY"),
        model_info=ModelInfo(
            vision=False,
            function_calling=True,
            json_output=True,
            family=ModelFamily.UNKNOWN,
            structured_output=True,
        ),
        # å¯ç”¨ token çº§åˆ«çš„æµå¼è¾“å‡º
        stream_options={"include_usage": True} if streaming else None,
    )
    
    agent = AssistantAgent(
        name="assistant",
        model_client=model_client,
        tools=[get_weather, search_information, calculate],
        system_message="""ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„ AI åŠ©æ‰‹ï¼Œå¯ä»¥ï¼š
        1. æŸ¥è¯¢å¤©æ°”ä¿¡æ¯
        2. æœç´¢ç›¸å…³ä¿¡æ¯
        3. è¿›è¡Œæ•°å­¦è®¡ç®—
        
        è¯·æ ¹æ®ç”¨æˆ·çš„è¯·æ±‚é€‰æ‹©åˆé€‚çš„å·¥å…·ã€‚""",
        reflect_on_tool_use=True,
    )
    
    return agent


async def _handle_streaming():
    """
    å¤„ç†æµå¼è¯·æ±‚ - ç”Ÿæˆå™¨å‡½æ•°
    
    å®æ—¶æµå¼è¿”å› LLM å“åº”ï¼Œå¹¶ç´¯ç§¯å®Œæ•´å“åº”ä¿å­˜åˆ°å¯¹è¯å†å²
    """
    if not AUTOGEN_AVAILABLE:
        yield {"chunk": "ï¼ˆæ¨¡æ‹Ÿå“åº”ï¼‰AutoGen æœªå®‰è£…", "type": "content"}
        yield {"chunk": "", "type": "end"}
        return
    
    try:
        agent = _create_agent(streaming=True)
        accumulated_content = ""
        
        # å°†å¯¹è¯å†å²è½¬æ¢ä¸º AutoGen æ¶ˆæ¯æ ¼å¼
        messages = []
        for msg in conversation_history:
            messages.append(TextMessage(content=msg["content"], source=msg["role"]))
        
        # åˆ›å»º CancellationToken
        cancellation_token = CancellationToken()
        
        # è¿è¡Œ Agent æµå¼è¾“å‡º
        async for message in agent.on_messages_stream(messages, cancellation_token):
            # æå–æ¶ˆæ¯å†…å®¹
            content = None
            
            # å¤„ç† Response ç±»å‹ï¼ˆåŒ…å« chat_messageï¼‰
            if hasattr(message, 'chat_message') and hasattr(message.chat_message, 'content'):
                content = message.chat_message.content
            # å¤„ç†ç›´æ¥åŒ…å« content çš„äº‹ä»¶ï¼ˆå¦‚ ThoughtEventï¼‰
            elif hasattr(message, 'content'):
                content = message.content
            
            # è¾“å‡ºæœ‰æ•ˆå†…å®¹
            if content and isinstance(content, str) and content.strip():
                accumulated_content += content
                yield {"chunk": content, "type": "content"}
        
        # ä¿å­˜åˆ°å¯¹è¯å†å²
        if accumulated_content:
            conversation_history.append({"role": "assistant", "content": accumulated_content})
        
        yield {"chunk": "", "type": "end"}
        
    except Exception as e:
        logger.error(f"æµå¼å¤„ç†é”™è¯¯: {str(e)}", exc_info=True)
        yield {"error": str(e), "type": "error"}


async def _handle_non_streaming():
    """
    å¤„ç†éæµå¼è¯·æ±‚ - è¿”å›å®Œæ•´å“åº”å­—å…¸
    
    è°ƒç”¨ Agentï¼Œæå–å“åº”ï¼Œä¿å­˜åˆ°å¯¹è¯å†å²
    """
    if not AUTOGEN_AVAILABLE:
        return {"result": "ï¼ˆæ¨¡æ‹Ÿå“åº”ï¼‰AutoGen æœªå®‰è£…ï¼Œè¯·å®‰è£…åä½¿ç”¨å®Œæ•´åŠŸèƒ½ã€‚"}
    
    try:
        agent = _create_agent()
        
        # å°†å¯¹è¯å†å²è½¬æ¢ä¸º AutoGen æ¶ˆæ¯æ ¼å¼
        messages = []
        for msg in conversation_history:
            messages.append(TextMessage(content=msg["content"], source=msg["role"]))
        
        # åˆ›å»º CancellationToken
        cancellation_token = CancellationToken()

        # è¿è¡Œ Agent
        response_message = await agent.on_messages(messages, cancellation_token)
        
        # æå–å“åº”å†…å®¹
        if response_message and hasattr(response_message, 'chat_message'):
            chat_msg = response_message.chat_message
            response = chat_msg.content if hasattr(chat_msg, 'content') else str(chat_msg)
        else:
            response = str(response_message) if response_message else "æœªç”Ÿæˆå“åº”"
        
        # ä¿å­˜åˆ°å¯¹è¯å†å²
        conversation_history.append({"role": "assistant", "content": response})
        
        return {"result": response}
        
    except Exception as e:
        logger.error(f"Agent æ‰§è¡Œé”™è¯¯: {str(e)}", exc_info=True)
        return {
            "error": f"Agent æ‰§è¡Œå¤±è´¥: {str(e)}",
            "error_type": type(e).__name__
        }


# å®šä¹‰ PPIO Agent Runtime å…¥å£ç‚¹ï¼ˆæ”¯æŒå¼‚æ­¥ï¼‰
@app.entrypoint
async def agent_invocation(request: dict, context: RequestContext):
    """
    AutoGen Agent å…¥å£ç‚¹ï¼ˆæ”¯æŒæµå¼å’Œå¤šè½®å¯¹è¯ï¼‰
    
    Args:
        request: è¯·æ±‚æ•°æ®ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
            - prompt: ç”¨æˆ·è¾“å…¥çš„æŸ¥è¯¢
            - streaming: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡ºï¼ˆå¯é€‰ï¼Œé»˜è®¤ Falseï¼‰
        context: è¯·æ±‚ä¸Šä¸‹æ–‡
            
    Returns:
        å“åº”æ•°æ®å­—å…¸ï¼ˆéæµå¼ï¼‰æˆ–ç”Ÿæˆå™¨ï¼ˆæµå¼ï¼‰
    """
    try:
        # è·å–è¯·æ±‚å‚æ•°
        prompt = request.get("prompt", "ä½ å¥½ï¼")
        streaming = request.get("streaming", False)
        
        # æ·»åŠ æ–°ç”¨æˆ·æ¶ˆæ¯åˆ°å…¨å±€å†å²
        conversation_history.append({"role": "user", "content": prompt})
        
        # æ ¹æ® streaming å‚æ•°é€‰æ‹©å¤„ç†å‡½æ•°
        if streaming:
            return _handle_streaming()
        else:
            return await _handle_non_streaming()
    
    except Exception as e:
        logger.error(f"Agent é”™è¯¯: {str(e)}", exc_info=True)
        return {
            "error": f"Agent é”™è¯¯: {str(e)}",
            "error_type": type(e).__name__
        }


@app.ping
def health_check() -> dict:
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {
        "status": "healthy",
        "service": "AutoGen Agent",
        "features": ["weather", "search", "calculate", "streaming", "multi-turn"]
    }


if __name__ == "__main__":
    print("\n" + "="*80)
    print("ğŸš€ å¯åŠ¨ Microsoft AutoGen Agent Runtime")
    print("="*80)
    print("ğŸ› ï¸  å¯ç”¨å·¥å…·ï¼šget_weather, search_information, calculate")
    print("ğŸ’¬ æ”¯æŒåŠŸèƒ½ï¼šæµå¼è¾“å‡ºã€å¤šè½®å¯¹è¯")
    print("ğŸ”— ç›‘å¬ç«¯å£ï¼š8080")
    print("="*80 + "\n")
    app.run(port=8080)

